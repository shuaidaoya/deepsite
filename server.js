import express from "express";
import path from "path";
import { fileURLToPath } from "url";
import dotenv from "dotenv";
import cookieParser from "cookie-parser";
import {
  createRepo,
  uploadFiles,
  whoAmI,
  spaceInfo,
  fileExists,
} from "@huggingface/hub";
import bodyParser from "body-parser";

import { PROVIDERS } from "./utils/providers.js";
import { COLORS } from "./utils/colors.js";
import { TEMPLATES, CDN_URLS } from "./utils/templates.js";

// Load environment variables from .env file
dotenv.config();

// æ£€æµ‹Vercelç¯å¢ƒ - Vercelä¼šè‡ªåŠ¨è®¾ç½®VERCELç¯å¢ƒå˜é‡
const isVercelEnvironment = process.env.VERCEL === '1' || process.env.VERCEL === 'true' || !!process.env.VERCEL;

// IPè®¿é—®é™åˆ¶ - å¦‚æœæœªé…ç½®æˆ–å€¼<=0åˆ™ä¸é™åˆ¶
const IP_RATE_LIMIT = parseInt(process.env.IP_RATE_LIMIT) || 0;
// ç”¨äºå­˜å‚¨IPè®¿é—®è®°å½•çš„ç¼“å­˜
const ipRequestCache = {};

const app = express();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const PORT = process.env.APP_PORT || 3000;
const MODEL_ID = process.env.OPENAI_MODEL || "deepseek-chat";
const OPENAI_BASE_URL = process.env.OPENAI_BASE_URL || "https://api.deepseek.com/v1";
const DEFAULT_MAX_TOKENS = process.env.DEFAULT_MAX_TOKENS || 6000;
const DEFAULT_TEMPERATURE = process.env.DEFAULT_TEMPERATURE || 0;

app.use(cookieParser());
app.use(bodyParser.json());

// ä¼˜åŒ–é™æ€æ–‡ä»¶è·¯å¾„å¤„ç†
const staticPath = isVercelEnvironment ? path.join(process.cwd(), "dist") : path.join(__dirname, "dist");
app.use(express.static(staticPath));

// IPé™æµä¸­é—´ä»¶ - æ£€æŸ¥æ¯ä¸ªIPçš„è®¿é—®é¢‘ç‡
app.use((req, res, next) => {
  // å¦‚æœæœªé…ç½®é™åˆ¶æˆ–é™åˆ¶å€¼<=0ï¼Œåˆ™è·³è¿‡é™æµæ£€æŸ¥
  if (IP_RATE_LIMIT <= 0) {
    req.rateLimit = { limited: false };
    return next();
  }
  
  // è·å–å®¢æˆ·ç«¯IPåœ°å€
  const clientIp = req.headers['x-forwarded-for'] || 
                   req.connection.remoteAddress || 
                   req.socket.remoteAddress;
                   
  // é™æ€èµ„æºè¯·æ±‚ä¸è®¡å…¥é™åˆ¶
  if (req.path.startsWith('/assets/') || 
      req.path.endsWith('.js') || 
      req.path.endsWith('.css') || 
      req.path.endsWith('.ico') || 
      req.path.endsWith('.png') || 
      req.path.endsWith('.jpg') || 
      req.path.endsWith('.svg')) {
    req.rateLimit = { limited: false };
    return next();
  }
  
  const now = Date.now();
  const hourAgo = now - 3600000; // 1å°æ—¶å‰çš„æ—¶é—´æˆ³
  
  // åˆå§‹åŒ–IPè®°å½•
  if (!ipRequestCache[clientIp]) {
    ipRequestCache[clientIp] = [];
  }
  
  // æ¸…ç†1å°æ—¶å‰çš„è¯·æ±‚è®°å½•
  ipRequestCache[clientIp] = ipRequestCache[clientIp].filter(timestamp => timestamp > hourAgo);
  
  // è®¡ç®—å½“å‰è¯·æ±‚æ•°å’Œå‰©ä½™è¯·æ±‚æ•°
  const requestCount = ipRequestCache[clientIp].length;
  const remainingRequests = IP_RATE_LIMIT - requestCount;
  
  // å°†é™æµä¿¡æ¯æ·»åŠ åˆ°è¯·æ±‚å¯¹è±¡ä¸­ï¼Œä¾›åç»­å¤„ç†ä½¿ç”¨
  req.rateLimit = {
    limited: requestCount >= IP_RATE_LIMIT,
    requestCount,
    remainingRequests,
    clientIp
  };
  
  // æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
  if (req.rateLimit.limited) {
    // æ‰¾å‡ºæœ€æ—©çš„è¯·æ±‚æ—¶é—´ï¼Œè®¡ç®—ä½•æ—¶å¯ä»¥å†æ¬¡è¯·æ±‚
    const oldestRequest = Math.min(...ipRequestCache[clientIp]);
    const resetTime = oldestRequest + 3600000; // æœ€æ—©çš„è¯·æ±‚æ—¶é—´ + 1å°æ—¶
    const waitTimeMs = resetTime - now;
    const waitTimeMinutes = Math.ceil(waitTimeMs / 60000); // è½¬æ¢ä¸ºåˆ†é’Ÿå¹¶å‘ä¸Šå–æ•´
    
    // è·å–å®¢æˆ·ç«¯å¯èƒ½çš„è¯­è¨€è®¾ç½®
    const clientLang = req.headers['accept-language'] || 'en';
    const isZhClient = clientLang.toLowerCase().includes('zh');
    
    console.log(`Rate limit exceeded for IP: ${clientIp}, can try again in ${waitTimeMinutes} minutes`);
    
    // æ ¹æ®è¯­è¨€è¿”å›åˆé€‚çš„æ¶ˆæ¯
    const message = isZhClient 
      ? `è¯·æ±‚é¢‘ç‡è¶…è¿‡é™åˆ¶ï¼Œè¯·åœ¨ ${waitTimeMinutes} åˆ†é’Ÿåå†è¯•`
      : `Too many requests. Please try again in ${waitTimeMinutes} minutes.`;
    
    return res.status(429).send({
      ok: false,
      message: message,
      waitTimeMinutes: waitTimeMinutes,
      resetTime: resetTime
    });
  }
  
  // è®°å½•æœ¬æ¬¡è¯·æ±‚æ—¶é—´æˆ³ï¼ˆåªåœ¨ä¸­é—´ä»¶ä¸­è®°å½•ï¼Œé¿å…é‡å¤è®¡æ•°ï¼‰
  ipRequestCache[clientIp].push(now);
  
  // å®šæœŸæ¸…ç†è¿‡æœŸIPè®°å½•(æ¯å°æ—¶)
  if (!global.ipCacheCleanupInterval) {
    global.ipCacheCleanupInterval = setInterval(() => {
      const cleanupTime = Date.now() - 3600000;
      for (const ip in ipRequestCache) {
        ipRequestCache[ip] = ipRequestCache[ip].filter(timestamp => timestamp > cleanupTime);
        // å¦‚æœæ²¡æœ‰è®°å½•ï¼Œåˆ é™¤è¯¥IPçš„ç¼“å­˜
        if (ipRequestCache[ip].length === 0) {
          delete ipRequestCache[ip];
        }
      }
      console.log(`IP cache cleanup completed. Active IPs: ${Object.keys(ipRequestCache).length}`);
    }, 3600000);
  }
  
  next();
});

const getPTag = (repoId) => {
  return `<p style="border-radius: 8px; text-align: center; font-size: 12px; color: #fff; margin-top: 16px;position: fixed; left: 8px; bottom: 8px; z-index: 10; background: rgba(0, 0, 0, 0.8); padding: 4px 8px;">Made with <img src="https://enzostvs-deepsite.hf.space/logo.svg" alt="DeepSite Logo" style="width: 16px; height: 16px; vertical-align: middle;display:inline-block;margin-right:3px;filter:brightness(0) invert(1);"><a href="https://enzostvs-deepsite.hf.space" style="color: #fff;text-decoration: underline;" target="_blank" >DeepSite</a> - <a href="https://enzostvs-deepsite.hf.space?remix=${repoId}" style="color: #fff;text-decoration: underline;" target="_blank" >ğŸ§¬ Remix</a></p>`;
};

// è·å–æ‰€æœ‰å¯ç”¨æ¨¡æ¿
app.get("/api/templates", (req, res) => {
  const templates = Object.keys(TEMPLATES).map(key => ({
    id: key,
    name: TEMPLATES[key].name,
    description: TEMPLATES[key].description,
  }));
  
  return res.status(200).send({
    ok: true,
    templates,
  });
});

// è·å–æŒ‡å®šæ¨¡æ¿çš„è¯¦ç»†ä¿¡æ¯
app.get("/api/templates/:id", (req, res) => {
  const { id } = req.params;
  
  if (!TEMPLATES[id]) {
    return res.status(404).send({
      ok: false,
      message: "Template not found",
    });
  }
  
  // æ¨¡æ¿ä¸­ç°åœ¨ç›´æ¥å¼•ç”¨CDN_URLSï¼Œä¸éœ€è¦æ›¿æ¢å˜é‡
  const html = TEMPLATES[id].html;
  
  return res.status(200).send({
    ok: true,
    template: {
      id,
      name: TEMPLATES[id].name,
      description: TEMPLATES[id].description,
      systemPrompt: TEMPLATES[id].systemPrompt,
      html: html
    },
  });
});

// æ£€æŸ¥OpenAIç¯å¢ƒå˜é‡é…ç½®çŠ¶æ€çš„API
app.get("/api/check-env", (req, res) => {
  // æ£€æŸ¥å„é¡¹ç¯å¢ƒå˜é‡æ˜¯å¦å·²é…ç½®
  const apiKeyConfigured = !!process.env.OPENAI_API_KEY;
  const baseUrlConfigured = !!process.env.OPENAI_BASE_URL;
  const modelConfigured = !!process.env.OPENAI_MODEL;
  const ipRateLimitConfigured = !!process.env.IP_RATE_LIMIT && parseInt(process.env.IP_RATE_LIMIT) > 0;
  
  return res.status(200).send({
    ok: true,
    env: {
      apiKey: apiKeyConfigured,
      baseUrl: baseUrlConfigured,
      model: modelConfigured,
      ipRateLimit: ipRateLimitConfigured
    },
    model: process.env.OPENAI_MODEL || "",
    ipRateLimit: parseInt(process.env.IP_RATE_LIMIT) || 0
  });
});

// æµ‹è¯•APIè¿æ¥
app.post("/api/test-connection", async (req, res) => {
  const { api_key, base_url, model } = req.body;
  
  try {
    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
    const apiKey = api_key || process.env.OPENAI_API_KEY;
    if (!apiKey) {
      return res.status(400).send({
        ok: false,
        message: "API key is required for testing",
      });
    }

    const baseUrl = base_url || OPENAI_BASE_URL;
    const modelId = model || MODEL_ID;

    // æ„å»ºç®€å•çš„æµ‹è¯•è¯·æ±‚
    const requestOptions = {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: modelId,
        messages: [
          {
            role: "user",
            content: "hi",
          },
        ],
        max_tokens: 50,  // é™åˆ¶è¿”å›é•¿åº¦ï¼ŒåŠ å¿«æµ‹è¯•é€Ÿåº¦
        temperature: 0   // å›ºå®šè¿”å›ç»“æœ
      })
    };

    console.log("Testing OpenAI API connection");
    console.log(`Testing API at: ${baseUrl}`);
    console.log(`Testing model: ${modelId}`);
    
    const response = await fetch(`${baseUrl}/chat/completions`, requestOptions);

    if (!response.ok) {
      const errorData = await response.json();
      return res.status(response.status).send({
        ok: false,
        message: errorData.error?.message || "Connection test failed",
      });
    }

    const data = await response.json();
    
    // éªŒè¯å“åº”ä¸­æ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹
    if (data && data.choices && data.choices[0] && data.choices[0].message) {
      return res.status(200).send({
        ok: true,
        message: "Connection test successful",
        response: data.choices[0].message.content
      });
    } else {
      return res.status(500).send({
        ok: false,
        message: "Received invalid response format"
      });
    }
  } catch (error) {
    console.error("Error testing connection:", error);
    return res.status(500).send({
      ok: false,
      message: error.message || "An error occurred during connection test",
    });
  }
});

// ä¼˜åŒ–æç¤ºè¯çš„æ¥å£
app.post("/api/optimize-prompt", async (req, res) => {
  const { 
    prompt, 
    language,
    api_key,
    base_url,
    model
  } = req.body;
  if (!prompt) {
    return res.status(400).send({
      ok: false,
      message: "Missing prompt field",
    });
  }

  try {
    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„API KEYï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
    const apiKey = api_key || process.env.OPENAI_API_KEY;
    if (!apiKey) {
      return res.status(500).send({
        ok: false,
        message: "OpenAI API key is not configured.",
      });
    }

    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„BASE URLå’ŒModel
    const baseUrl = base_url || OPENAI_BASE_URL;
    const modelId = model || MODEL_ID;

    // æ ¹æ®è¯­è¨€è®¾ç½®ç³»ç»Ÿæç¤ºè¯
    const systemPrompt = language === 'zh'
      ? "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æç¤ºè¯ä¼˜åŒ–åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ”¹è¿›ç”¨æˆ·çš„æç¤ºè¯ï¼Œä½¿å…¶æ›´åŠ æ¸…æ™°ã€å…·ä½“å’Œæœ‰æ•ˆã€‚ä¿æŒç”¨æˆ·çš„åŸå§‹æ„å›¾ï¼Œä½†ä½¿æç¤ºè¯æ›´åŠ ç»“æ„åŒ–ï¼Œæ›´å®¹æ˜“è¢«AIç†è§£ã€‚åªè¾“å‡ºä¼˜åŒ–åçš„æç¤ºè¯æ–‡æœ¬ï¼Œä¸è¦ä½¿ç”¨Markdownè¯­æ³•ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€è¯„è®ºæˆ–é¢å¤–æ ‡è®°ã€‚å¿…è¦æ—¶å¯ä»¥ä½¿ç”¨æ¢è¡Œç¬¦æˆ–ç©ºæ ¼æ¥æ ¼å¼åŒ–æ–‡æœ¬ï¼Œä½¿å…¶æ›´æ˜“è¯»ã€‚"
      : "You are a professional prompt optimization assistant. Your task is to improve the user's prompt to make it clearer, more specific, and more effective. Maintain the user's original intent but make the prompt more structured and easier for AI to understand. Output only the plain text of the optimized prompt without any Markdown syntax, explanations, comments, or additional markers. You may use <br> and spaces to format the text when necessary to improve readability.";

    const messages = [
      {
        role: "system",
        content: systemPrompt,
      },
      {
        role: "user",
        content: prompt,
      },
    ];

    const requestOptions = {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: modelId,
        messages,
        temperature: 0.7,
        max_tokens: 2000
      })
    };

    console.log("Sending prompt optimization request to OpenAI API");
    console.log(`Using API at: ${baseUrl}`);
    console.log(`Using model: ${modelId}`);
    
    const response = await fetch(`${baseUrl}/chat/completions`, requestOptions);

    if (!response.ok) {
      console.error(`OpenAI API error: ${response.status} ${response.statusText}`);
      
      try {
        const error = await response.json();
        return res.status(response.status).send({
          ok: false,
          message: error?.message || "Error calling OpenAI API",
        });
      } catch (parseError) {
        return res.status(response.status).send({
          ok: false,
          message: `OpenAI API error: ${response.status} ${response.statusText}`,
        });
      }
    }

    const data = await response.json();
    const optimizedPrompt = data.choices?.[0]?.message?.content?.trim();

    return res.status(200).send({
      ok: true,
      optimizedPrompt,
    });
  } catch (error) {
    console.error("Error optimizing prompt:", error);
    return res.status(500).send({
      ok: false,
      message: error.message || "An error occurred while optimizing the prompt",
    });
  }
});

app.post("/api/deploy", async (req, res) => {
  const { html, title } = req.body;
  if (!html || !title) {
    return res.status(400).send({
      ok: false,
      message: "Missing required fields",
    });
  }

  return res.status(200).send({
    ok: true,
    message: "Deployment feature has been removed as it required Hugging Face login",
  });
});

app.post("/api/ask-ai", async (req, res) => {
  const { 
    prompt, 
    html, 
    previousPrompt, 
    templateId, 
    language, 
    ui, 
    tools, 
    max_tokens, 
    temperature,
    api_key,
    base_url,
    model
  } = req.body;
  if (!prompt) {
    return res.status(400).send({
      ok: false,
      message: "Missing required fields",
    });
  }

  // è·å–å®¢æˆ·ç«¯IP - ç”¨äºæ—¥å¿—è®°å½•
  const clientIp = req.headers['x-forwarded-for'] || 
                   req.connection.remoteAddress || 
                   req.socket.remoteAddress;
                   
  // ä½¿ç”¨ä¸­é—´ä»¶å·²è®¡ç®—çš„é™æµä¿¡æ¯è®°å½•æ—¥å¿—
  if (req.rateLimit) {
    if (req.rateLimit.limited === false) {
      console.log(`API request from IP: ${clientIp}, rate limit: unlimited or not applicable`);
    } else {
      console.log(`API request from IP: ${clientIp}, requests this hour: ${req.rateLimit.requestCount}/${IP_RATE_LIMIT}, remaining: ${req.rateLimit.remainingRequests}`);
    }
  } else {
    console.log(`API request from IP: ${clientIp}, rate limit information not available`);
  }

  // è®¾ç½®å“åº”å¤´
  res.setHeader("Content-Type", "text/plain");
  res.setHeader("Cache-Control", "no-cache");
  res.setHeader("Connection", "keep-alive");
  // æ·»åŠ ä»¥ä¸‹å“åº”å¤´ä»¥ä¼˜åŒ–æµå¼ä¼ è¾“
  res.setHeader("Transfer-Encoding", "chunked");
  res.setHeader("X-Accel-Buffering", "no"); // ç¦ç”¨ Nginx ç¼“å†²
  res.setHeader("X-Content-Type-Options", "nosniff");
  res.setHeader("Keep-Alive", "timeout=120"); // ä¿æŒè¿æ¥120ç§’
  res.flushHeaders(); // ç«‹å³å‘é€å“åº”å¤´
  
  const selectedProvider = PROVIDERS["openai"];

  try {
    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„API KEYï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
    const apiKey = api_key || process.env.OPENAI_API_KEY;
    if (!apiKey) {
      return res.status(500).send({
        ok: false,
        message: "OpenAI API key is not configured.",
      });
    }

    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„BASE URLï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
    const baseUrl = base_url || OPENAI_BASE_URL;
    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„Modelï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
    const modelId = model || MODEL_ID;

    console.log(`Using OpenAI API at: ${baseUrl}`);
    console.log(`Using model: ${modelId}`);
    
    // è·å–åŸºç¡€ç³»ç»Ÿæç¤ºè¯
    let systemPrompt = templateId && TEMPLATES[templateId] 
      ? TEMPLATES[templateId].systemPrompt 
      : TEMPLATES.vanilla.systemPrompt;
    
    // å¦‚æœæœ‰é€‰æ‹©ç»„ä»¶åº“ï¼Œä»…å½“é€‰æ‹©Vue3æ¡†æ¶æ—¶æ‰æ·»åŠ ç›¸å…³æç¤º
    if (ui && ui !== templateId && templateId === 'vue3') {
      const uiTemplate = TEMPLATES[ui];
      if (uiTemplate) {
        // ä»ç»„ä»¶åº“æç¤ºè¯ä¸­æå–å…³é”®éƒ¨åˆ†å¹¶æ·»åŠ åˆ°ç³»ç»Ÿæç¤ºä¸­
        systemPrompt += ` Also, use ${uiTemplate.name} component library with CDN: `;
        
        if (ui === 'elementPlus') {
          systemPrompt += `CSS: ${CDN_URLS.ELEMENT_PLUS_CSS}, JS: ${CDN_URLS.ELEMENT_PLUS_JS}, Icons: ${CDN_URLS.ELEMENT_PLUS_ICONS}.`;
        } else if (ui === 'naiveUI') {
          systemPrompt += `${CDN_URLS.NAIVE_UI}.`;
        }
      }
    }
    
    // å¦‚æœæœ‰é€‰æ‹©å·¥å…·åº“ï¼Œæ·»åŠ ç›¸å…³æç¤º
    if (tools && tools.length > 0) {
      systemPrompt += " Include the following additional libraries: ";
      
      tools.forEach((tool, index) => {
        if (tool === 'tailwindcss') {
          systemPrompt += `Tailwind CSS (use <script src="${CDN_URLS.TAILWIND}"></script>)`;
        } else if (tool === 'vueuse') {
          systemPrompt += `VueUse (use <script src="${CDN_URLS.VUEUSE_SHARED}"></script> and <script src="${CDN_URLS.VUEUSE_CORE}"></script>)`;
        } else if (tool === 'dayjs') {
          systemPrompt += `Day.js (use <script src="${CDN_URLS.DAYJS}"></script>)`;
        } else if (tool === 'element-plus-icons') {
          systemPrompt += `Element Plus Icons (use <script src="${CDN_URLS.ELEMENT_PLUS_ICONS}"></script>)`;
        }
        
        if (index < tools.length - 1) {
          systemPrompt += ", ";
        }
      });
      
      systemPrompt += ". Make sure to use the correct syntax for all the frameworks and libraries.";
    }
    
    // æ ¹æ®è¯­è¨€è®¾ç½®æ·»åŠ æ³¨é‡Šè¯­è¨€æç¤º
    if (language === 'zh') {
      systemPrompt += " è¯·ä½¿ç”¨ä¸­æ–‡ç¼–å†™æ‰€æœ‰çš„æ³¨é‡Šã€‚";
    } else if (language === 'en') {
      systemPrompt += " Please write all comments in English.";
    }
    
    // æ—¥å¿—è¾“å‡ºé€‰æ‹©çš„é…ç½®
    console.log("Template configuration:");
    console.log(`- Framework: ${templateId}`);
    console.log(`- UI Library: ${ui || 'None'}`);
    console.log(`- Tools: ${tools ? tools.join(', ') : 'None'}`);
    console.log(`- Language: ${language || 'default'}`);
    
    const messages = [
      {
        role: "system",
        content: systemPrompt,
      },
    ];

    if (previousPrompt) {
      messages.push({
        role: "user",
        content: previousPrompt,
      });
    }

    if (html) {
      messages.push({
        role: "assistant",
        content: `The current code is: ${html}.`,
      });
    }

    messages.push({
      role: "user",
      content: prompt,
    });

    const requestOptions = {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: modelId,
        messages,
        stream: true,
        max_tokens: max_tokens || parseInt(DEFAULT_MAX_TOKENS),
        temperature: temperature !== undefined ? parseFloat(temperature) : parseFloat(DEFAULT_TEMPERATURE)
      })
    };

    console.log(`Sending request to OpenAI API with model: ${modelId}`);
    console.log(`Using max_tokens: ${max_tokens || DEFAULT_MAX_TOKENS}, temperature: ${temperature !== undefined ? temperature : DEFAULT_TEMPERATURE}`);
    console.log("Request URL:", `${baseUrl}/chat/completions`);
    console.log("Request headers:", {
      ...requestOptions.headers,
      "Authorization": "Bearer [API_KEY_HIDDEN]"
    });
    console.log("Request body:", JSON.parse(requestOptions.body));
    
    const response = await fetch(`${baseUrl}/chat/completions`, requestOptions);

    if (!response.ok) {
      console.error(`OpenAI API error: ${response.status} ${response.statusText}`);
      
      try {
        // æ£€æŸ¥ Content-Type æ˜¯å¦ä¸º JSON
        const contentType = response.headers.get("Content-Type");
        console.log(`Response Content-Type: ${contentType}`);
        
        if (contentType && contentType.includes("application/json")) {
          const error = await response.json();
          console.error("OpenAI API error details:", error);
          return res.status(response.status).send({
            ok: false,
            message: error?.message || "Error calling OpenAI API",
          });
        } else {
          // å¦‚æœä¸æ˜¯ JSONï¼Œç›´æ¥è¯»å–æ–‡æœ¬
          const errorText = await response.text();
          console.error("OpenAI API error text:", errorText);
          return res.status(response.status).send({
            ok: false,
            message: errorText || `OpenAI API error: ${response.status} ${response.statusText}`,
          });
        }
      } catch (parseError) {
        // å¤„ç† JSON è§£æé”™è¯¯
        console.error("Error parsing API response:", parseError);
        return res.status(response.status).send({
          ok: false,
          message: `OpenAI API error: ${response.status} ${response.statusText}`,
        });
      }
    }

    // å¤„ç† OpenAI æµå¼å“åº”
    const reader = response.body.getReader();
    const decoder = new TextDecoder("utf-8");
    let completeResponse = "";

    console.log("Starting to process stream response");

    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) {
          console.log("Stream completed");
          break;
        }

        // æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦å·²ç»æ–­å¼€è¿æ¥
        if (res.writableEnded) {
          console.log("Client disconnected, stopping stream");
          reader.cancel("Client disconnected");
          break;
        }

        // è§£æ SSE æ ¼å¼çš„æ•°æ®
        const chunk = decoder.decode(value);
        
        // å°è¯•å¤„ç†ä¸åŒæ ¼å¼çš„æµå¼å“åº”
        const lines = chunk.split("\n");
        let processedAnyLine = false;
        
        for (const line of lines) {
          // æ ‡å‡† OpenAI æ ¼å¼
          if (line.startsWith("data: ")) {
            processedAnyLine = true;
            if (line.includes("[DONE]")) {
              console.log("Received [DONE] signal");
              continue;
            }
            
            try {
              const data = JSON.parse(line.replace("data: ", ""));
              const content = data.choices?.[0]?.delta?.content || "";
              
              if (content) {
                // æ£€æŸ¥è¿æ¥æ˜¯å¦ä¸­æ–­
                if (!res.writableEnded) {
                  res.write(content);
                  completeResponse += content;
                  
                  if (completeResponse.includes("</html>")) {
                    console.log("Found </html> tag, ending stream");
                    break;
                  }
                } else {
                  console.log("Cannot write to closed response");
                  break;
                }
              }
            } catch (e) {
              console.error("Error parsing JSON from SSE line:", e);
              console.log("Problematic line:", line);
              // ç»§ç»­å¤„ç†å…¶ä»–è¡Œ
            }
          }
        }
        
        // å¦‚æœæ²¡æœ‰è¯†åˆ«å‡ºæ ‡å‡† SSE æ ¼å¼ï¼Œå°è¯•ç›´æ¥å¤„ç†æ•´ä¸ªå—
        if (!processedAnyLine && chunk.trim()) {
          try {
            // å°è¯•ä½œä¸º JSON è§£ææ•´ä¸ªå“åº”
            const jsonData = JSON.parse(chunk);
            if (jsonData.choices && jsonData.choices[0]) {
              const content = jsonData.choices[0].message?.content || jsonData.choices[0].delta?.content || "";
              if (content && !res.writableEnded) {
                res.write(content);
                completeResponse += content;
              }
            }
          } catch (e) {
            // ä¸æ˜¯ JSONï¼Œç›´æ¥ä½œä¸ºæ–‡æœ¬å¤„ç†
            if (!res.writableEnded) {
              res.write(chunk);
              completeResponse += chunk;
            }
          }
        }
        
        if (completeResponse.includes("</html>")) {
          console.log("Found </html> tag in complete response, ending stream");
          break;
        }
      }
      
      console.log("Stream processing completed");
      if (!res.writableEnded) {
        res.end();
      }
    } catch (streamError) {
      console.error("Error processing stream:", streamError);
      // æ£€æŸ¥æ˜¯å¦æ˜¯å®¢æˆ·ç«¯ä¸­æ–­è¿æ¥
      if (streamError.message && (streamError.message.includes("aborted") || streamError.message.includes("canceled"))) {
        console.log("Client aborted the request");
      }
      
      if (!res.headersSent) {
        res.status(500).send({
          ok: false,
          message: "Error processing response stream"
        });
      } else if (!res.writableEnded) {
        res.end();
      }
    }
  } catch (error) {
    if (error.message.includes("exceeded your monthly included credits")) {
      return res.status(402).send({
        ok: false,
        openProModal: true,
        message: error.message,
      });
    }
    if (!res.headersSent) {
      res.status(500).send({
        ok: false,
        message:
          error.message || "An error occurred while processing your request.",
      });
    } else {
      // Otherwise end the stream
      res.end();
    }
  }
});

app.get("/api/remix/:username/:repo", async (req, res) => {
  const { username, repo } = req.params;
  const { hf_token } = req.cookies;

  const token = hf_token || process.env.DEFAULT_HF_TOKEN;

  const repoId = `${username}/${repo}`;
  const space = await spaceInfo({
    name: repoId,
  });

  if (!space || space.sdk !== "static" || space.private) {
    return res.status(404).send({
      ok: false,
      message: "Space not found",
    });
  }

  const url = `https://huggingface.co/spaces/${repoId}/raw/main/index.html`;
  const response = await fetch(url);
  if (!response.ok) {
    return res.status(404).send({
      ok: false,
      message: "Space not found",
    });
  }
  let html = await response.text();
  // remove the last p tag including this url https://enzostvs-deepsite.hf.space
  html = html.replace(getPTag(repoId), "");

  res.status(200).send({
    ok: true,
    html,
  });
});

app.get("*", (_req, res) => {
  // åœ¨Vercelä¸Šä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
  const indexPath = isVercelEnvironment 
    ? path.join(process.cwd(), "dist", "index.html")
    : path.join(__dirname, "dist", "index.html");
  res.sendFile(indexPath);
});

// Vercelåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä¸éœ€è¦ç›‘å¬ç‰¹å®šç«¯å£ï¼Œå› ä¸ºå®ƒä¼šä»£ç†è¯·æ±‚
if (isVercelEnvironment) {
  console.log('Running on Vercel - no need to listen on a specific port');
} else {
  app.listen(PORT, () => {
    console.log(`Server is running on port ${PORT}`);
  });
}

// å¯¼å‡ºExpressåº”ç”¨å®ä¾‹ï¼ŒVerceléœ€è¦å®ƒ
export default app;
